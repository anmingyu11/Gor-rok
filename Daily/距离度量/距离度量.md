[](https://blog.csdn.net/ljyljyok/article/details/81509027)

[](https://zhuanlan.zhihu.com/p/58819850)

## 度量空间&测距函数

#### 度量空间

**度量空间（metric space）是一种具有度量函数（metric function）或者叫做距离函数（distance function）的集合，此函数定义集合内所有元素间的距离，被称为集合上的metric。**

**度量空间中最符合直观理解的是三维欧氏空间，事实上，metric的概念是欧氏距离性质的推广。**

#### 距离函数

首先，我们需要对”距离”本身进行一些约束。我们所描述的距离，指的是**度量空间**（Metric space）的距离。良好的测距函数应具备以下特征：

- **距离大于等于0；**
- **距离是对称的，即 a 到 b 的距离应等于 b 到 a 的距离；**
- **相同的输入，距离为0；**
- **满足三角不等式；**

-------------------------------------------------

# GOGO1

聚类分析中如何度量两个对象之间的相似性呢？

一般有两种方法，一种是对所有对象作特征投影，另一种则是距离计算。

前者主要从直观的图像上反应对象之间的相似度关系，而后者则是通过衡量对象之间的差异度来反应对象之间的相似度关系。

如图（1）所示：假设X坐标轴为时间，Y坐标轴为繁殖率，则可以看出三种不同的物种在不同时间段的繁殖情况，由于分别在10,40,80三个数值附近，因此根据繁殖率这一特征便可以分辨出三种物种。特征投影比较直观，但是对象之间的相似性直接的依赖于测量的特征，换一种特征可能会有相反的效果。

距离计算是最为常见的相似度度量方法：

通常的对象$a$，$b$之间的相似度为$Sim(a,b)$，对象$a$，$b$的测量距离为$d(a,b)$，则一般采取$Sim(a,b) = \frac{1}{(1 + d(a,b))}$得到相似度。

常见的距离计算方法有：

#### 1. 欧氏距离：

可以简单的描述为多维空间的点点之间的几何距离，
$$
Distance(x,y) = \sqrt{\sum_{k=1}^{n}(x_{k} - y_{k})^2}
$$
**需要注意的是，欧式距离通常采用的是原始数据，而并非规划化后的数据，比如有一属性在$1-100$内取值，那么便可以直接使用，而并非一定要将其归一到$[0,1]$区间使用。这样的话，欧式距离的原本意义便被消除了，正是因为这样，所以其优势在于新增对象不会影响到任意两个对象之间的距离。然而，如果对象属性的度量标准不一样，如在度量分数时采取十分制和百分制，对结果影响较大。**

#### 2. 曼哈顿距离

如果欧式距离看成是多维空间对象点点的直线距离，那么曼哈顿距离就是计算从一个对象到另一个对象所经过的折线距离，有时也可以进一步的描述为多维空间中对象在各维的平均差，取平均差之后的计算公式为
$$
Distance(x,y) = \frac{1}{n}\sum_{k=1}^{n}|x_{k}-y_{k}|
$$
**需要注意的是，曼哈顿距离取消了欧式距离的平方，因此使得离群点的影响减弱。**

#### 3. 切比雪夫距离：

切比雪夫距离主要表现为在多维空间中，对象从某个位置转移到另外一个对象所消耗的最少距离（这种距离更加形象的体现了第一节中提到的编辑距离概念），因此可以简单的描述为用一维属性决定某对象属于哪个簇，
$$
Distance(x,y) = \mathop{Max}\limits_{k+1}^{m}(x_{k},y_{k})
$$
**这就好比我们去辨别一项罕见的现象一样，如果两个对象都存在这一罕见现象，那么这两个对象应该属于同一个簇。**

#### 4. 闵氏距离：

可以简单的描述为针对不同的属性给予不同的权重值，决定其属于那个簇，
$$
Distance(x,y) = (\sum_{k=1}^{n}|x_k - y_k|^p)^{\frac{1}{p}}
$$

#### 5. 余弦相似度：

可以简单的描述为空间中两个对象的属性所构成的向量之间的夹角大小。
$$
Distance(\vec{x},\vec{y}) = cos(\vec{x},\vec{y}) = 
\frac{x^Ty}{||x||||y||}
=
\frac{\sum_{k=1}^{n}x_{ik}y_{jk}}{\sum_{k=1}^{n}x_{ik}^2\sum_{k=1}^{n}y_{ik}^2}
$$
即当两个向量方向完全相同时，相似度为1，当两个向量方向相反时，则为-1。

#### 6. 皮尔森相似度：

可以描述为不同对象偏离拟合的中心线程度，可以进一步的理解为，许多对象的属性拟合成一条直线或者曲线，计算每个对象相对于这条线的各属性偏离程度，
$$
a
$$
其中c为共有属性

 #### 7. 修正的余弦相似度：

由(5)可以看出，如果对于不同维的计算尺度，则会有所偏差。
$$
a
$$


#### 8. Jaccard相似度

Jaccard相似度常用于二值型数据的相似度计算。
$$
a
$$
在数据挖掘中，经常将属性值二值化，通过计算Jaccard相似度，可以简单快速的得到两个对象的相似程度。当然，对于不同的属性，这种二值型程度是不一样的，比如，在中国，熟悉汉语的两个人相似度与熟悉英语的两个人相似度是不同的，因为发生的概率不同。所以通常会对Jaccard计算变换，变换的目的主要是为了拉开或者聚合某些属性的距离

#### 9. 汉明距离

可以描述为将同等长度的字符串由其中一个变换到另一个的最小替换次数。如将a(11100)变换为b(00010)，则其距离为4，汉明距离主要是为了解决在通信中数据传输时，改变的二进制位数，也称为信号距离。
$$
a
$$


#### 10. 加权的欧式距离：

由上面的闵氏距离可知，其存在一定的缺陷，如何去减弱这种缺陷呢？一种简单的办法是对不同属性设置不同的权重，各权重之和为1，这样依然可以保证相似度的统一性，但是这种权重该如何选择呢？一种加权的欧式距离方法便可以将各维属性变换到标准化值。假设所有对象的X的均值为m,方差为s，则标准化后的值=（标准化前的值-各属性的均值）/各属性的标准差，所以加权的欧式距离为：
$$
a
$$

#### 11. 相关距离：

相关距离是用来衡量随机变量X,Y之间的相关程度的一种方法，取值为[-1,1]，且系数越大，相关度越高。当X,Y线性相关时，若为正线性相关时则为1，相关距离=1-相关系数，相关系数的计算为：
$$
a
$$

#### 12.马氏距离

即数据的协方差距离，与欧式距离不同的是它考虑到各属性之间的联系，如考虑性别信息时会带来一条关于身高的信息，因为二者有一定的关联度，而且独立于测量尺度。
$$
a
$$
其中，XY为样本中的对象，S为协方差矩阵。

通过以上方法的计算，便可以得到两个对象之间的相似度（距离），在实际的计算当中，应该根据不同的对象其属性特点进行有效选择，对象的距离计算对于聚类算法的过程十分重要，直接影响着算法的有效性，所以实际选择时应当仔细选择。
$$
a
$$
