# DeepWalk: Online Learning of Social Representations

## ABSTRACT

我们提出了一种新的学习网络中顶点的潜在表示的方法 DeepWalk。这些的表示将社会关系编码在一个连续的向量空间中，这很容易被统计学习模型所学习。DeepWalk 通过将单词序列转化成图推动了语言模型和无监督特征学习(或深度学习)的最新改进。

DeepWalk 通过使用截断 random walk 获得的局部信息，将 walk 等同于句子来学习潜在表示。我们展示了 DeepWalk 在 BlogCatalog、Flickr 和YouTube等社交网络的几个多标签 network 分类任务上的潜在表示。我们的研究结果表明，DeepWalk 优于具有挑战性的 baseline，该 baseline 允许对 network 进行全局观察，特别是在存在缺失信息的情况下。当标签数据稀疏时，DeepWalk 的表示法可以提供比对照方法高出 10% 的 F1-score。在一些实验中，DeepWalk 的表示能够在使用少于 60% 的训练数据的情况下优于所有 baseline 方法。

DeepWalk 也是可扩展的。 它是一种在线学习算法，可以建立有用的增量结果，并且可以并行化。 这些性质使其适合各种实际应用，例如网络分类和异常检测。

## 1. INTRODUCTION

![Fig1](/Users/helloword/Anmingyu/Gor-rok/Papers/Embedding/DeepWalkOnlineLearningofSocialRepresentations/Fig1.png)

**图1：我们提出的方法在 $\mathbb{R}^d$ 中学习 social interactions 的潜在空间表示。所学习的表示对 community structrue 进行编码，因此可以很容易地被标准分类方法利用。这里，我们在Zachary的空手道网络[44]上使用我们的方法来生成 $\mathbb{R}^2$ 中的潜在表示。注意输入图中的 community structrue 与 Embedding 之间的对应关系。顶点颜色表示输入 graph 的基于模块化的聚类。**

network 表示的稀疏性既是优点也是缺点。稀疏性可以设计高效的离散算法，但也使其难以在统计学习中推广。机器学习在 network 中的应用(如 network 分类[16,37]、内容推荐[12]、异常检测[6]和缺失链接预测[23])必须能够处理这种稀疏性才能生存。

在本文中，我们首次将深度学习(无监督特征学习)[3]技术引入到 network 分析中，这些技术在 NLP 中已经被证明是成功的。我们开发了一个算法(DeepWalk)，它通过模拟一系列短的随机游走来学习图的顶点的 social 表示。social 表示是顶点的潜在特征，可以捕捉邻域相似性和社区成员关系。这些潜在表示将社会关系编码在维数相对较少的连续向量空间中。DeepWalk 将神经语言模型推广到处理由一组由随机游走生成的 walk 组成的特殊语言。这些神经语言模型已经被用来捕捉人类语言的语义和语法结构[7]，甚至逻辑类比[29]。

DeepWalk 将图作为输入，并生成潜在表示作为输出。将我们的方法应用于经过充分研究的 Karate network 的结果如图1所示。图1a显示了常见的由 force-directed layouts 表示的图。图1b显示了具有 2个潜在维度的方法的输出。除了惊人的相似性之外，我们注意到(1b)的线性可分离部分对应于在输入图(1a)中通过 modularity maximization 找到的簇(显示为顶点颜色)。

为了展示 DeepWalk 在现实世界场景中的潜力，我们评估了它在大型异构图中挑战多标签 network 分类问题上的表现。在关系分类问题中，特征向量之间的联系违背了传统的 i.i.d.假设。解决这个问题的技术通常使用近似推理技术[32]来利用依赖信息来改善分类结果。我们通过学习图的标签无关表示来远离这些方法。我们的表示质量不受顶点的标签的影响，因此它们可以在任务之间共享。

DeepWalk 在创建 Social 维度方面优于其他潜在表示方法[39，41]，特别是在 labeld 节点稀缺的情况下。使用非常简单的线性分类器(例如，Logistic回归)，我们的表示就有可能实现出色的性能。我们的表示是通用的，可以与任何分类方法(包括迭代推理方法)相结合。DeepWalk实现了所有这一切，同时也是一种可以并行化的在线算法。我们的贡献如下：

- 我们引入深度学习作为分析 graph 的工具，以构建适合统计学习建模的健壮表示。DeepWalk 学习短随机游走中存在的结构规律性。
- 我们在几个社交网络上广泛评估了我们在多标签分类任务上的表示。在标签稀疏的情况下，我们表现出显著的分类性能提高，在我们考虑的最稀疏的问题上，得到了 Micro F1 的 5% - 10% 的改进。在某些情况下，即使训练数据少于 60%，DeepWalk 的表现也能超过竞争对手。
- 我们通过使用并行实现构建 web-scale 图的表示(如YouTube)来演示算法的可扩展性。此外，我们还描述了构建我们的方法的 stream 版本所需的最小更改。

论文的其余部分安排如下。在第 2 节和第 3 节中，我们讨论 network 中分类的问题表述，以及它与我们的工作的关系。在第四节中，我们介绍了 social 表示学习方法 DeepWalk。第 5 节概述了我们的实验，并在第 6 节介绍了结果。最后，我们在第 7 节讨论了相关工作，并得出了我们的结论。

## 2. PROBLEM DEFINITION

考虑将一个社会网络中的成员划分为一个或多个类别的问题。设 $G=(V，E)$，其中 $V$ 代表 network 成员，$E$ 是他们的连接，$E \subseteq (V \times V)$，$G_L=(V，E，X，Y)$ 是一个部分标记了的社交网络，属性 $X\in\mathbb{R}^{|V|×S}$ 其中 $S$ 是每个属性向量的特征空间大小，$Y\in R^{|V| \times |\mathcal{Y}|}$ , $\mathcal{Y}$ 是标签集。

在传统的机器学习分类设置中，我们的目标是学习一个假设 $H$，它将 $X$ 的元素映射到 $\mathcal{Y}$ 的标签集。在我们的例子中，我们可以利用 Embedding 在 $G$ 结构中的例子上的的重要依赖信息来实现卓越的表现。

在文献中，这被称为关系分类（或集体分类问题[37]）。关系分类的传统方法将问题视为无向马尔可夫网络中的推理，然后使用迭代近似推理算法（如迭代分类算法[32]、吉布斯采样[15]或标签松弛[19]）来计算给定 network 的标签的后验分布。

我们提出了一种不同的方法来捕获 network 的拓扑信息。我们提出了一种无监督方法，该方法学习捕获与标签分布无关的图结构的特征，而不是将标签空间混合为特征空间的一部分。

结构表示和标记任务之间的这种分离避免了迭代方法[34]中可能出现的 cascading 错误。此外，相同的表示可以用于与该 network 相关的多个分类问题。

我们的目标是学习 $X_E \in R^{|V|×d} $ ，其中 $d$ 是少量的潜在维度。这些低维表示是分布式的；这意味着每个 social phenomena 都由维度的子集来表示，每个维度都贡献了空间所表达的社会概念的子集。

使用这些结构特征，我们将扩大属性空间以帮助分类决策。这些特征是通用的，可以用于任何分类算法 (包括迭代方法)。然而，我们认为这些特征的最大效用是它们易于与简单的机器学习算法集成。正如我们将在第 6 节中介绍的那样，它们在真实 network 中进行了适当的扩展。

## 3. LEARNING SOCIAL REPRESENTATIONS

我们试图学习具有以下特点的 social 表示：

- Adaptability：真正的社交网络是不断发展的；新的社会关系不应该要求从头再来一遍的学习过程。
- Community aware：潜在维度之间的距离应该代表一个衡量标准，用于评估网络中相应成员之间的 social 相似性。这允许在具有同质性的网络中进行泛化。
- Low dimensional：当标签数据稀缺时，低维模型可以更好地泛化，并加快收敛和推理。
- Continuous：我们需要潜在的表示来对连续空间中的部分 social member 进行建模。 除了提供 social member 的细微差别外，连续表示还具有 social 之间的平滑决策边界，从而可以进行更可靠的分类。

我们的方法通过使用最初为语言建模设计的优化技术，从短随机游走 stream 中学习顶点的表示来满足这些要求。在这里，我们回顾了随机游走和语言建模的基础知识，并描述了它们的组合如何满足我们的要求。

## 3.1 Random Walks

我们将 root 是顶点 $v_i$ 的随机游走表示为 $\mathcal{W}_{v_i}$。它是一个包含随机变量 $\mathcal{W}^1_{v_i}， \cdots， \mathcal{W}^2_{v_i} $ 的随机过程，$\mathcal{W}^{k+1}_{v_i}$ 是从顶点 $v_k$ 的邻域中随机选择的顶点(注：这里应该是 $v_i$ 吧？)。在内容推荐[12]和社区检测[2]中，许多问题都使用了随机游走作为相似度量。它们也是一类输出敏感算法的基础，该算法使用与输入图的大小成线性关系的时间复杂度计算 local community 结构信息[38]。

正是这种与本地结构的联系促使我们使用短随机游走流作为我们从网络中提取信息的基本工具。 除了捕获 community 信息之外，使用随机游走作为我们算法的基础还为我们提供了两个理想的属特性。 首先，局部搜索很容易并行化。 几个随机游走（位于不同的线程，进程或机器中）可以同时浏览同一图的不同部分。 其次，依靠从短随机游走中获得的信息，可以在不需要全局重新计算的情况下适应图结构中的微小变化。 我们可以用新的随机游走迭代更新已学习到的模型时间复杂度同样是图大小的次线性。

## 3.2 Connection: Power laws

在选择了在线随机游走作为我们捕获图结构的基元之后，我们现在需要一种合适的方法来捕获这些信息。如果连通图的度分布遵循幂律（i.e. scale-free），我们观察到短随机游游走出现顶点的频率也将遵循幂律分布。

自然语言中的词频遵循类似的分布，语言建模技术解释了这种分布行为。为了强调这种相似性，我们在图2中显示了两种不同的幂律分布。第一种来自无标度图上的一系列短期随机游走，第二种来自英文维基百科(Wikipedia)100,000篇文章的文本。

我们工作的一个核心贡献是，用于建模自然语言（其中符号频率遵循幂律分布（或 Zipf's定律））的技术可以被重新用于建模 network 中的 social comunity。我们在本节的其余部分回顾了语言建模方面不断进步的工作，并将其转换为学习满足我们标准的顶点表示。

![Fig2](/Users/helloword/Anmingyu/Gor-rok/Papers/Embedding/DeepWalkOnlineLearningofSocialRepresentations/Fig2.png)

**Figure 2: The distribution of vertices appearing in short random walks (2a) follows a power-law, much like the distribution of words in natural language (2b).**

## 3.3 Language Modeling

语言建模的目标是估计特定单词序列出现在语料库中的可能性。更正式地说，给定一个单词序列 $W_1^n=（w_0，w_1，\cdots，w_n) $, 其中 $w_i\in\mathcal{V}$  ($\mathcal{V}$ 是词汇），我们希望在所有训练语料中最大化 $Pr(w_n|w_0，w_1，\cdots，w_{n-1}) $ 。最近在表示学习方面的工作专注在使用概率神经网络来构建单词的一般表示，这将语言建模的范围扩展到其原始目标之外。

在这项工作中，我们提出了一种语言建模的推广，通过一系列短随机游走来探索图。这些游走可以被认为是特殊语言中的短句和短语；直接模拟是根据随机游走中迄今为止访问的所有以前的顶点来估计观察顶点 $v_i$ 的可能性，即
$$
Pr(v_i | (v_1, v_2, \cdots , v_{i−1}))
\qquad (1)
$$
我们的目标是学习一个潜在表示，而不仅仅是节点共现的概率分布，因此我们引入了一个映射函数 $\Phi$ 。这个映射 $\Phi$ 代表与图中每个顶点 $v$ 相关的潜在社会表示。（在实践中，我们用一个自由参数的 $|V|×d$ 矩阵来表示 $\Phi$ ，这个矩阵将在以后用作我们的 $X_E$）。那么，问题是估计似然：
$$
Pr(v_i|(\Phi(v_1),\Phi(v_2),\cdots,\Phi(v_{i-1})))
\qquad (2)
$$
然而，随着游走长度的增长，计算这种条件概率变得不可行。

最近在语言建模 [27,28] 中的一个松弛条件使预测问题迎刃而解。首先，它不使用上下文来预测一个缺失的单词，而是使用一个单词来预测上下文。其次，上下文由给定单词的左右两侧出现的单词组成。最后，它移除了问题的顺序约束，而是要求模型在不知道其与给定单词偏移的情况下，最大化上下文中出现任何单词的概率。就顶点表示建模而言，这产生了优化问题：
$$
\mathop{minimize}_{\Phi}− log \Pr(\{v_{i−w}, \cdots , v_{i+w}\} \backslash v_i | \Phi(v_i))
\qquad (3)
$$
我们发现这些松弛条件特别适合于 social 表示学习。首先，顺序独立假设更好地捕捉了随机游走提供的“接近”感。此外，这种松弛对于通过构建小模型来加快训练时间非常有用，因为每次给出一个顶点。

从 Eq 3 中求解优化问题建立了捕获顶点间局部图结构中共享相似性的表示。具有相似邻域的顶点将获得相似的表示(编码 co-citation 相似性)，允许在机器学习任务中泛化。

通过结合 truncate random walk 和 language model，我们生成了一种满足我们所有需求的方法。这种方法生成了存在于连续向量空间中的低维的表示。它的表示编码了社区成员的潜在形式，因为这种方法输出了使用的的中间表示，所以它可以适应不断变化的 network 拓扑结构。

